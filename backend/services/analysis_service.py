import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from cachetools import TTLCache, cached
from concurrent.futures import ThreadPoolExecutor
import requests
from pykrx import stock
from dotenv import load_dotenv
import os

from .macro_service import get_fred_data

load_dotenv()

# ìºì‹œ ì„¤ì •
risk_cache = TTLCache(maxsize=100, ttl=600)
yield_gap_cache = TTLCache(maxsize=100, ttl=3600) # 1ì‹œê°„ ìºì‹œ

# API í‚¤ ì„¤ì •
ecos_key = os.getenv("ECOS_API_KEY")

# 3. Risk Radar (ìˆ˜ì •: ë°ì´í„° ë³‘í•© ë¡œì§ ê°œì„ )
@cached(cache=risk_cache) 
def get_risk_ratio():
    try:
        # 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ë³‘ë ¬)
        # auto_adjust=True: ìˆ˜ì • ì£¼ê°€ ë°˜ì˜
        print("ğŸ“¥ Downloading Risk Data (parallel)...")
        tickers = {"gold": "GC=F", "silver": "SI=F", "sp500": "^GSPC"}
        downloads = {}
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {
                executor.submit(
                    yf.download, ticker, period="5y", interval="1d",
                    progress=False, auto_adjust=True
                ): name
                for name, ticker in tickers.items()
            }
            for future in futures:
                name = futures[future]
                downloads[name] = future.result()
        gold, silver, sp500 = downloads["gold"], downloads["silver"], downloads["sp500"]

        # 2. ì•ˆì „í•œ ì¢…ê°€ ì¶”ì¶œ í—¬í¼ (yfinance ë²„ì „ í˜¸í™˜ì„± í™•ë³´)
        def get_safe_close(df, name):
            if df is None or df.empty:
                print(f"âŒ {name}: Empty DataFrame")
                return None
            
            # [ì¤‘ìš”] Timezone ì œê±° ë° 00:00:00 ì •ê·œí™” (ë³‘í•© ì „ í•„ìˆ˜)
            if isinstance(df.index, pd.DatetimeIndex):
                if df.index.tz is not None:
                    # tz_localize(None)ì€ UTC -> Local ì‹œê°„ ë³€í™˜ì´ ì•„ë‹ˆë¼ ê·¸ëƒ¥ tz ì •ë³´ë§Œ ì œê±°í•¨
                    df.index = df.index.tz_localize(None)
                # ë‚ ì§œë§Œ ë‚¨ê¸°ê³  ì‹œê°„ ì œê±° (ì„œë¡œ ë‹¤ë¥¸ ê±°ë˜ì†Œ ë§ˆê° ì‹œê°„ ì°¨ì´ ë¬´ì‹œ)
                df.index = df.index.normalize()

            # 1) MultiIndex ì²˜ë¦¬
            if isinstance(df.columns, pd.MultiIndex):
                # 'Close' ë ˆë²¨ì´ ìˆìœ¼ë©´ ê°€ì ¸ì˜¤ê¸°
                if 'Close' in df.columns.get_level_values(0):
                    series = df.xs('Close', axis=1, level=0)
                    # ë§Œì•½ seriesê°€ ë˜ DataFrameì´ë©´ (Tickerê°€ ì»¬ëŸ¼ì¸ ê²½ìš°)
                    if isinstance(series, pd.DataFrame):
                        return series.iloc[:, 0]
                    return series
            
            # 2) ì¼ë°˜ Index ('Close' or 'Price')
            if 'Close' in df.columns:
                return df['Close']
            if 'Price' in df.columns:
                return df['Price']
                
            # 3) 1ì°¨ì› Seriesì¸ ê²½ìš°
            if isinstance(df, pd.Series):
                 return df

            # 4) ì • ì•ˆë˜ë©´ ì²« ë²ˆì§¸ ì»¬ëŸ¼
            print(f"âš ï¸ {name}: 'Close' not found. Using {df.columns[0]}")
            return df.iloc[:, 0]

        g_series = get_safe_close(gold, "Gold")
        s_series = get_safe_close(silver, "Silver")
        sp_series = get_safe_close(sp500, "S&P500")

        if g_series is None or s_series is None or sp_series is None:
            raise ValueError("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (Empty Data)")

        # ì´ë¦„ ë¶€ì—¬ (concatì‹œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©ë¨)
        g_series.name = 'gold'
        s_series.name = 'silver'
        sp_series.name = 'sp500'

        # 3. ë°ì´í„° ë³‘í•©
        # axis=1 (Outer Join) -> ê²°ì¸¡ì¹˜ëŠ” NaNìœ¼ë¡œ ë“¤ì–´ê°
        df = pd.concat([g_series, s_series, sp_series], axis=1)
        
        # 4. ì „ì²˜ë¦¬
        # ffill()ë¡œ í•˜ë£¨ì´í‹€ ì°¨ì´ë‚˜ëŠ” ë°ì´í„° ì±„ì›€ (íœ´ì¥ì¼, ì‹œì°¨ ë“±)
        df = df.ffill().dropna()

        # 5. ë¹„ìœ¨ ê³„ì‚°
        df['ratio'] = df['gold'] / df['silver']
        
        # ë¬´í•œëŒ€/NaN ì œê±°
        df = df.replace([np.inf, -np.inf], np.nan).dropna()
        
        # 6. ê²°ê³¼ í¬ë§·íŒ…
        df = df.reset_index()
        # index ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ê·œí™”
        if 'Date' in df.columns:
            df.rename(columns={'Date': 'date'}, inplace=True)
        elif 'index' in df.columns:
            df.rename(columns={'index': 'date'}, inplace=True)

        df['date'] = df['date'].dt.strftime('%Y-%m-%d')
        df['ratio'] = df['ratio'].round(2)
        df['sp500'] = df['sp500'].round(2)

        final_data = df[['date', 'ratio', 'sp500']].to_dict('records')

        if len(final_data) < 10:
            raise ValueError(f"ìœ íš¨í•œ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŒ: {len(final_data)} rows")

        print(f"âœ… Risk Data Loaded: {len(final_data)} rows")
        return final_data

    except Exception as e:
        print(f"âŒ [Risk Logic Error]: {e}")
        import traceback
        traceback.print_exc()
        
        # --- Mock Data ìƒì„± ë¡œì§ (ë¹„ìƒìš©) ---
        print("âš ï¸ Risk ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ Mock Data ìƒì„±")
        base_sp = 4500
        base_ratio = 80
        # KST ê¸°ì¤€ ì˜¤ëŠ˜
        today = datetime.now(ZoneInfo("Asia/Seoul"))
        mock_result = []
        for i in range(200):
            d = today - timedelta(days=200-i)
            mock_result.append({
                "date": d.strftime("%Y-%m-%d"),
                "ratio": round(base_ratio + (i % 10) * 0.5, 2),
                "sp500": round(base_sp + (i * 5), 2)
            })
        return mock_result



# 5. Yield Gap (Market Gauge)
@cached(cache=yield_gap_cache)
def get_yield_gap_data():
    """
    ë¯¸êµ­ ë° í•œêµ­ ì‹œì¥ì˜ ì¼ë“œê°­(Yield Gap) ì •ë³´ë¥¼ ê°€ì ¸ì˜´
    ë¯¸êµ­: S&P 500 PER ì—­ìˆ˜ - US 10Y Yield
    í•œêµ­: KOSPI PER ì—­ìˆ˜ - KR 10Y Yield
    """
    
    def calculate_judgment(current, avg, market_type="US"):
        diff = current - avg
        if market_type == "US":
            # US Judgment: "ì €í‰ê°€" / "ì ì •" / "ê³ í‰ê°€(ê³¼ì—´)"
            if diff > 0.5: return "ì €í‰ê°€"
            if diff < -0.5: return "ê³ í‰ê°€(ê³¼ì—´)"
            return "ì ì •"
        else:
            # KR Judgment: "ì ê·¹ ë§¤ìˆ˜" / "ê´€ë§" / "ë§¤ë„"
            if diff > 1.0: return "ì ê·¹ ë§¤ìˆ˜"
            if diff < -0.5: return "ë§¤ë„"
            return "ê´€ë§"

    # --- 1. US Market (S&P 500) ---
    us_data = {"current": 0, "avg": 0, "status": "ë°ì´í„° ì—†ìŒ", "pe": 0, "yield": 0}
    try:
        # yfinanceë¡œ SPY(S&P 500 Proxy) ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        spy = yf.Ticker("SPY")
        
        # PER êµ¬í•˜ê¸° (trailingPE ìš°ì„ , ì—†ìœ¼ë©´ forwardPE)
        try:
            current_pe = spy.info.get('trailingPE')
            if not current_pe:
                current_pe = spy.info.get('forwardPE')
        except:
            current_pe = 25.0 # Fallback
            
        if not current_pe: current_pe = 25.0
        
        # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
        current_yield_10y = 0
        # 10ë…„ë¬¼ êµ­ì±„ ê¸ˆë¦¬
        current_yield_10y = 0
        # auto_adjust=Trueë¡œ í†µì¼í•˜ì—¬ ë°ì´í„° êµ¬ì¡° ë‹¨ìˆœí™”
        tnx = yf.download("^TNX", period="5d", progress=False, auto_adjust=True)
        
        if not tnx.empty:
            # Robust extraction logic
            val = None
            # 1. MultiIndex handling
            if isinstance(tnx.columns, pd.MultiIndex):
                if 'Close' in tnx.columns.get_level_values(0):
                    val = tnx.xs('Close', axis=1, level=0).iloc[-1]
                    if isinstance(val, pd.Series): val = val.iloc[0]
            # 2. Single Index
            elif 'Close' in tnx.columns:
                val = tnx['Close'].iloc[-1]
            # 3. Fallback
            else:
                 val = tnx.iloc[-1, 0]
            
            if val is not None:
                current_yield_10y = float(val)
        
        # ì¼ë“œê°­ ê³„ì‚°
        current_gap = (1 / current_pe) * 100 - current_yield_10y
        
        # 5ë…„ í‰ê·  (FRED ë°ì´í„° í™œìš©)
        # KST ê¸°ì¤€ ì˜¤ëŠ˜
        now_kst = datetime.now(ZoneInfo("Asia/Seoul"))
        start_5y = (now_kst - timedelta(days=1825)).strftime('%Y-%m-%d')
        end_now = now_kst.strftime('%Y-%m-%d')
        
        # 10ë…„ë¬¼ ê¸ˆë¦¬ íˆìŠ¤í† ë¦¬
        yield_10y_hist = get_fred_data("DGS10", start_5y, end_now)
        avg_yield_5y = 0.0
        if not yield_10y_hist.empty and "DGS10" in yield_10y_hist:
             avg_yield_5y = yield_10y_hist["DGS10"].mean()
        else:
             avg_yield_5y = 3.0 # Fallback
        
        # S&P 500 5ë…„ í‰ê·  PER (ì •í™•í•œ íˆìŠ¤í† ë¦¬ëŠ” ìœ ë£Œ ë°ì´í„°ì¸ ê²½ìš°ê°€ ë§ì•„ ìƒìˆ˜ ê·¼ì‚¬ ë˜ëŠ” ê³„ì‚°)
        # S&P 500 í‰ê·  PERì€ ì•½ 20~25 ì‚¬ì´
        avg_pe_5y = 22.0
        avg_gap_5y = (1 / avg_pe_5y) * 100 - avg_yield_5y
        
        us_data = {
            "current": round(current_gap, 2),
            "avg": round(avg_gap_5y, 2),
            "status": calculate_judgment(current_gap, avg_gap_5y, "US"),
            "pe": round(current_pe, 1),
            "yield": round(current_yield_10y, 2)
        }
    except Exception as e:
        print(f"âŒ [US Yield Gap Error]: {e}")
        import traceback
        traceback.print_exc()

    # --- 2. KR Market (KOSPI) ---
    kr_data = {"current": 0, "avg": 0, "status": "ë°ì´í„° ì—†ìŒ", "pe": 0, "yield": 0}
    try:
        now_kst = datetime.now(ZoneInfo("Asia/Seoul"))
        today_str = now_kst.strftime("%Y%m%d")
        
        # 1) KOSPI PER (pykrx)
        curr_pe_kr = 0
        # ìµœê·¼ 5ì¼ ì¤‘ ë°ì´í„° ìˆëŠ” ë‚  ì°¾ê¸°
        for i in range(5):
            target_date = (now_kst - timedelta(days=i)).strftime("%Y%m%d")
            try:
                # 1001 = ì½”ìŠ¤í”¼
                # [Fix] PyKrx API ë¶ˆì•ˆì • ë° ë¡œê¹… ë²„ê·¸ì— ëŒ€í•œ ë°©ì–´ ì½”ë“œ
                try:
                    df_fund = stock.get_index_fundamental(target_date, target_date, "1001")
                    if not df_fund.empty:
                        # pykrx ë²„ì „ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ë³´í†µ 'PER'
                        if 'PER' in df_fund.columns:
                            curr_pe_kr = df_fund['PER'].iloc[-1]
                            break
                except Exception as e:
                    # JSONDecodeError, Logging Error ë“± ë¬´ì‹œí•˜ê³  ë„˜ì–´ê°
                    print(f"âš ï¸ PyKrx Fetch Warning ({target_date}): {e}")
                    continue
            except:
                continue
        
        if curr_pe_kr == 0: curr_pe_kr = 12.0 # Fallback
        
        # 2) KR 10Y Yield (ECOS API)
        kr_yield = 3.5 # Fallback
        if ecos_key:
            # 817Y002(ì‹œì¥ê¸ˆë¦¬ ì¼ë³„), 010210000(êµ­ê³ ì±„ 10ë…„)
            # ìµœê·¼ ë°ì´í„°ë§Œ í•„ìš”í•˜ë¯€ë¡œ ì‹œì‘ì¼ì„ 7ì¼ ì „ìœ¼ë¡œ ì„¤ì •
            start_recent = (now_kst - timedelta(days=7)).strftime("%Y%m%d")
            url = f"http://ecos.bok.or.kr/api/StatisticSearch/{ecos_key}/json/kr/1/10/817Y002/D/{start_recent}/{today_str}/010210000"
            resp = requests.get(url, timeout=10) # Timeout added
            if resp.status_code == 200:
                data = resp.json()
                if 'StatisticSearch' in data:
                    kr_yield = float(data['StatisticSearch']['row'][-1]['DATA_VALUE'])
        
        current_gap_kr = (1 / curr_pe_kr) * 100 - kr_yield
        
        # 3) 5ë…„ í‰ê· 
        # KOSPI 5ë…„ PER í‰ê· 
        avg_pe_kr_5y = 11.0 # Fallback
        start_5y_kr = (now_kst - timedelta(days=1825)).strftime('%Y%m%d')
        try:
             # [Fix] PyKrx API ë¶ˆì•ˆì • ë° ë¡œê¹… ë²„ê·¸ì— ëŒ€í•œ ë°©ì–´ ì½”ë“œ
             try:
                df_hist_pe = stock.get_index_fundamental(start_5y_kr, today_str, "1001")
                if not df_hist_pe.empty and 'PER' in df_hist_pe.columns:
                    avg_pe_kr_5y = df_hist_pe['PER'].replace(0, np.nan).dropna().mean()
             except Exception as e:
                 print(f"âš ï¸ PyKrx History Warning: {e}")
        except Exception as e:
             print(f"PyKrx Hist Error: {e}")
             
        # KR 10Y 5ë…„ ê¸ˆë¦¬ í‰ê·  (ECOS)
        avg_yield_kr_5y = 2.5 # Fallback
        if ecos_key:
            url_avg = f"http://ecos.bok.or.kr/api/StatisticSearch/{ecos_key}/json/kr/1/2000/817Y002/D/{start_5y_kr}/{today_str}/010210000"
            resp_avg = requests.get(url_avg, timeout=10) # Timeout added
            if resp_avg.status_code == 200:
                data = resp_avg.json()
                if 'StatisticSearch' in data:
                    vals = [float(r['DATA_VALUE']) for r in data['StatisticSearch']['row']]
                    if vals:
                        avg_yield_kr_5y = sum(vals) / len(vals)
        
        avg_gap_kr_5y = (1 / avg_pe_kr_5y) * 100 - avg_yield_kr_5y
        
        kr_data = {
            "current": round(current_gap_kr, 2),
            "avg": round(avg_gap_kr_5y, 2),
            "status": calculate_judgment(current_gap_kr, avg_gap_kr_5y, "KR"),
            "pe": round(curr_pe_kr, 1),
            "yield": round(kr_yield, 2)
        }
    except Exception as e:
        print(f"âŒ [KR Yield Gap Error]: {e}")

    return {
        "us": us_data,
        "kr": kr_data
    }

# 6. Rate Spread (Base Rate vs Call Rate)
@cached(cache=TTLCache(maxsize=100, ttl=86400))
def get_rate_spread_data():
    """
    ì½œê¸ˆë¦¬(Call Rate)ì™€ í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬(Base Rate)ë¥¼ ë¹„êµí•˜ì—¬ Spreadë¥¼ ê³„ì‚°
    Data Source: ECOS API
    - ê¸°ì¤€ê¸ˆë¦¬: 722Y001 (ì •ì±…ê¸ˆë¦¬) -> 0101000 (í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬)
    - ì½œê¸ˆë¦¬: 817Y002 (ì‹œì¥ê¸ˆë¦¬) -> 010101000 (ì½œê¸ˆë¦¬ 1ì¼)
    """
    
    # ECOS API Helper
    def get_ecos_series(stat_code, item_code, start_date, end_date):
        if not ecos_key:
            return pd.Series(dtype=float)
            
        url = f"http://ecos.bok.or.kr/api/StatisticSearch/{ecos_key}/json/kr/1/10000/{stat_code}/D/{start_date}/{end_date}/{item_code}"
        try:
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                if 'StatisticSearch' in data and 'row' in data['StatisticSearch']:
                    rows = data['StatisticSearch']['row']
                    # DataFrame ë³€í™˜
                    df = pd.DataFrame(rows)
                    df['TIME'] = pd.to_datetime(df['TIME'], format='%Y%m%d')
                    df['DATA_VALUE'] = pd.to_numeric(df['DATA_VALUE'])
                    df = df.set_index('TIME')
                    return df['DATA_VALUE']
        except Exception as e:
            print(f"âš ï¸ ECOS Fetch Error ({stat_code}-{item_code}): {e}")
            
        return pd.Series(dtype=float)

    try:
        now_kst = datetime.now(ZoneInfo("Asia/Seoul"))
        end_str = now_kst.strftime("%Y%m%d")
        # ìµœê·¼ 10ë…„ (ë„‰ë„‰í•˜ê²Œ 3700ì¼)
        start_str = (now_kst - timedelta(days=3700)).strftime("%Y%m%d")
        
        # 1. ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print("ğŸ“¥ Downloading Rate Data (ECOS)...")
        # ê¸°ì¤€ê¸ˆë¦¬ (722Y001 / 0101000)
        base_series = get_ecos_series("722Y001", "0101000", start_str, end_str)
        # ì½œê¸ˆë¦¬ (817Y002 / 010101000)
        call_series = get_ecos_series("817Y002", "010101000", start_str, end_str)
        
        if base_series.empty or call_series.empty:
            raise ValueError("ECOS Data Empty")
            
        # 2. ë°ì´í„° ë³‘í•©
        base_series.name = 'base_rate'
        call_series.name = 'call_rate'
        
        # Outer Joinìœ¼ë¡œ ë‚ ì§œ ë§ì¶¤
        df = pd.concat([base_series, call_series], axis=1)
        df = df.ffill().dropna()
        
        # í•„í„°ë§ ì œê±° (Frontendì—ì„œ ì²˜ë¦¬)
        
        # 3. Spread ê³„ì‚° (ê¸°ì¤€ê¸ˆë¦¬ - ì½œê¸ˆë¦¬) -> ë³´í†µ ì½œê¸ˆë¦¬ê°€ ê¸°ì¤€ê¸ˆë¦¬ë³´ë‹¤ ë†’ìœ¼ë©´ ìœ ë™ì„± ë¶€ì¡±
        # User Request: [ê¸°ì¤€ê¸ˆë¦¬ - ì½œê¸ˆë¦¬]
        df['spread'] = df['base_rate'] - df['call_rate']
        
        # 4. í¬ë§·íŒ…
        df = df.reset_index()
        df.rename(columns={'index': 'date', 'TIME': 'date'}, inplace=True)
        
        # ë‚ ì§œ í¬ë§· ë³€ê²½
        df['date'] = df['date'].dt.strftime('%Y-%m-%d')
        df['base_rate'] = df['base_rate'].round(2)
        df['call_rate'] = df['call_rate'].round(2)
        df['spread'] = df['spread'].round(2)
        
        result = df[['date', 'base_rate', 'call_rate', 'spread']].to_dict('records')
        
        print(f"âœ… Rate Spread Data Loaded: {len(result)} rows")
        return result

    except Exception as e:
        print(f"âŒ [Rate Spread Error]: {e}")
        # Mock Data
        print("âš ï¸ Rate Spread Mock Data Used")
        mock = []
        curr = now_kst
        base = 3.50
        # 10ë…„ì¹˜ Mock ë°ì´í„° (3650ì¼)
        for i in range(3650):
            d = curr - timedelta(days=3650-i)
            # ì½œê¸ˆë¦¬ëŠ” ê¸°ì¤€ê¸ˆë¦¬ ê·¼ì²˜ì—ì„œ ë³€ë™
            call = base + (np.sin(i / 5) * 0.1) 
            spread = base - call
            mock.append({
                "date": d.strftime("%Y-%m-%d"),
                "base_rate": base,
                "call_rate": round(call, 2),
                "spread": round(spread, 2)
            })
        return mock

# 7. US Rate Spread (FFTR vs EFFR)
@cached(cache=TTLCache(maxsize=100, ttl=86400))
def get_us_rate_spread_data():
    """
    ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬(FFTR Upper)ì™€ ì‹¤íš¨ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬(EFFR)ë¥¼ ë¹„êµí•˜ì—¬ Spread ê³„ì‚°
    Data Source: FRED
    - FFTR: DFEDTARU (Federal Funds Target Range - Upper Limit)
    - EFFR: DFF (Effective Federal Funds Rate)
    """
    try:
        now_kst = datetime.now(ZoneInfo("Asia/Seoul"))
        # ìµœê·¼ 10ë…„ ì¹˜ ë°ì´í„°
        end_date = now_kst
        start_date = now_kst - timedelta(days=3700)
        
        # FRED ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (macro_service í•¨ìˆ˜ ì¬ì‚¬ìš©)
        print("ğŸ“¥ Downloading US Rate Data (FRED)...")
        # 1. FFTR (Base Rate)
        df_fftr = get_fred_data("DFEDTARU", start_date, end_date)
        # 2. EFFR (Call Rate)
        df_effr = get_fred_data("DFF", start_date, end_date)
        
        if df_fftr.empty or df_effr.empty:
             # FRED API í‚¤ê°€ ì—†ê±°ë‚˜ í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ
             raise ValueError("FRED Data Empty")
             
        # ë°ì´í„°í”„ë ˆì„ ë³‘í•© ì¤€ë¹„
        df_fftr = df_fftr.rename(columns={"DFEDTARU": "base_rate"})
        df_effr = df_effr.rename(columns={"DFF": "call_rate"})
        
        # 'calculated_value' ì»¬ëŸ¼ ì œê±° (get_fred_dataì—ì„œ ìƒì„±ë¨)
        if 'calculated_value' in df_fftr.columns: del df_fftr['calculated_value']
        if 'calculated_value' in df_effr.columns: del df_effr['calculated_value']

        # Join
        df = pd.concat([df_fftr, df_effr], axis=1)
        
        # ì „ì²˜ë¦¬ (ì£¼ë§/ê³µíœ´ì¼ ffill)
        df = df.ffill().dropna()
        
        # Spread ê³„ì‚° (Base - Call)
        # ë¯¸êµ­ì€ ë³´í†µ EFFRì´ FFTR ë²”ìœ„ ë‚´ì— ìˆì–´ì•¼ í•¨. 
        # Base(ìƒë‹¨) - Call(ì‹¤íš¨) > 0 ì´ì–´ì•¼ ì •ìƒ. 
        # Callì´ Baseë¥¼ ëš«ìœ¼ë©´ ìœ ë™ì„± ê²½ìƒ‰ ì‹ í˜¸.
        df['spread'] = df['base_rate'] - df['call_rate']
        
        # í¬ë§·íŒ…
        df = df.reset_index()
        # index ì´ë¦„ì´ DATEê°€ ì•„ë‹ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì•ˆì „ì¥ì¹˜
        if 'index' in df.columns:
             df.rename(columns={'index': 'date'}, inplace=True)
        elif 'DATE' in df.columns:
             df.rename(columns={'DATE': 'date'}, inplace=True)
             
        df['date'] = df['date'].dt.strftime('%Y-%m-%d')
        df['base_rate'] = df['base_rate'].round(2)
        df['call_rate'] = df['call_rate'].round(2)
        df['spread'] = df['spread'].round(2)
        
        result = df[['date', 'base_rate', 'call_rate', 'spread']].to_dict('records')
        
        print(f"âœ… US Rate Spread Data Loaded: {len(result)} rows")
        return result

    except Exception as e:
        print(f"âŒ [US Rate Spread Error]: {e}")
        # Mock Data (10ë…„ì¹˜)
        print("âš ï¸ US Rate Spread Mock Data Used")
        mock = []
        curr = datetime.now(ZoneInfo("Asia/Seoul"))
        base = 5.50
        for i in range(3650):
            d = curr - timedelta(days=3650-i)
            # EFFRì€ ë³´í†µ FFTRë³´ë‹¤ ì•½ê°„ ë‚®ìŒ
            call = base - 0.05 + (np.sin(i / 100) * 0.1)
            spread = base - call
            mock.append({
                "date": d.strftime("%Y-%m-%d"),
                "base_rate": base,
                "call_rate": round(call, 2),
                "spread": round(spread, 2)
            })
        return mock
